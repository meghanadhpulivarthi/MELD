{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9589fdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2eb3e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_VIDEO_PATH =\"./data/pickles/train.pkl\"\n",
    "VAL_VIDEO_PATH =\"./data/pickles/dev.pkl\"\n",
    "TEST_VIDEO_PATH =\"./data/pickles/test.pkl\"\n",
    "\n",
    "train_video_emb = pickle.load(open(TRAIN_VIDEO_PATH, \"rb\"))\n",
    "val_video_emb = pickle.load(open(VAL_VIDEO_PATH,\"rb\"))\n",
    "test_video_emb = pickle.load(open(TEST_VIDEO_PATH, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a81beab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_video_emb = pd.DataFrame(train_video_emb).loc[\"video_features\"]\n",
    "val_video_emb = pd.DataFrame(val_video_emb).loc[\"video_features\"]\n",
    "test_video_emb = pd.DataFrame(test_video_emb).loc[\"video_features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02576616",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_video_emb = pd.DataFrame(train_video_emb).loc[\"video_features\"].apply(np.ravel).apply(lambda arr: np.pad(arr, pad_width=(0, 180224-arr.shape[0])))\n",
    "val_video_emb = pd.DataFrame(val_video_emb).loc[\"video_features\"].apply(np.ravel).apply(lambda arr: np.pad(arr, pad_width=(0, 180224-arr.shape[0])))\n",
    "test_video_emb = pd.DataFrame(test_video_emb).loc[\"video_features\"].apply(np.ravel).apply(lambda arr: np.pad(arr, pad_width=(0, 180224-arr.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebcdab2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1_0      [[0.011106509026273262, 0.04718035275929226, 0...\n",
       "1_3      [[0.015098579258906867, 0.04213589226354767, 0...\n",
       "1_4      [[0.005982336429889133, 0.027534894560523188, ...\n",
       "1_6      [[0.006809703862492025, 0.032477708086196266, ...\n",
       "1_8      [[0.00865120851115894, 0.06901358270037608, 0....\n",
       "                               ...                        \n",
       "108_5    [[0.021402748670429243, 0.03855056391410193, 0...\n",
       "108_6    [[0.009176798904517901, 0.0272982339837231, 0....\n",
       "109_4    [[0.0077250037534126, 0.01337237350543254, 0.0...\n",
       "111_0    [[0.012533136074229538, 0.053418867576108996, ...\n",
       "112_0    [[0.00989493214077471, 0.010479544271642398, 0...\n",
       "Name: video_features, Length: 1108, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_video_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84e73c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0_2       [[0.012740027625412176, 0.01689307334099398, 0...\n",
       "1_0       [[0.02273952029665867, 0.012984730675280652, 0...\n",
       "2_0       [[0.016300556172714583, 0.00491589682760573, 0...\n",
       "2_1       [[0.010934121189539079, 0.0037774264428040486,...\n",
       "2_9       [[0.00737365250132438, 0.009779059544447037, 0...\n",
       "                                ...                        \n",
       "279_2     [[0.015999244002425802, 0.025744970290860876, ...\n",
       "279_3     [[0.015321349295101917, 0.020270294324049268, ...\n",
       "279_4     [[0.024855712519631278, 0.022914816081657796, ...\n",
       "279_7     [[0.005832571119431089, 0.013968805802223105, ...\n",
       "279_10    [[0.0009170512481931627, 0.01467845581792865, ...\n",
       "Name: video_features, Length: 2610, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_video_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df42f261",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_video_emb, val_video_emb, test_video_emb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0dc4b715",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pickle.load(open(\"./data/pickles/data_emotion.p\",\"rb\"))\n",
    "revs, W, word_idx_map, vocab, _, label_index = x[0], x[1], x[2], x[3], x[4], x[5]\n",
    "train_data, val_data, test_data = {},{},{}\n",
    "\n",
    "def get_word_indices(data_x):\n",
    "    length = len(data_x.split())\n",
    "    return np.array([word_idx_map[word] for word in data_x.split()] + [0]*(50-length))[:50]\n",
    "\n",
    "for i in range(len(revs)):\n",
    "\n",
    "    utterance_id = revs[i]['dialog']+\"_\"+revs[i]['utterance']\n",
    "    sentence_word_indices = get_word_indices(revs[i]['text'])\n",
    "    label = label_index[revs[i]['y']]\n",
    "\n",
    "    if revs[i]['split']==\"train\":\n",
    "        train_data[utterance_id]=(sentence_word_indices,label)\n",
    "    elif revs[i]['split']==\"val\":\n",
    "        val_data[utterance_id]=(sentence_word_indices,label)\n",
    "    elif revs[i]['split']==\"test\":\n",
    "        test_data[utterance_id]=(sentence_word_indices,label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a986d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = train_data.keys()\n",
    "val_ids = val_data.keys()\n",
    "test_ids = test_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb0a9f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0_0        [[0.014226668649600444, 0.016732933856248546, ...\n",
       "0_0        [[0.0010872683657894345, 0.03182079256443694, ...\n",
       "0_0        [[0.015387712856396018, 0.016883689112090414, ...\n",
       "0_1        [[0.01655472303415718, 0.01806011063367376, 0....\n",
       "0_1        [[0.006492410952383432, 0.051149999605998246, ...\n",
       "                                 ...                        \n",
       "1035_0     [[0.009770837997137759, 0.030200655503257717, ...\n",
       "1035_2     [[0.009664520370904766, 0.04341559068840073, 0...\n",
       "1035_5     [[0.0027781594157775904, 0.03625946895533295, ...\n",
       "1036_10    [[0.007684331566888093, 0.014693151943533095, ...\n",
       "1036_15    [[0.005370471104941787, 0.024580842935958167, ...\n",
       "Name: video_features, Length: 12403, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[train_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfaf6d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1_0      [0.004155361811718552, 0.016543615196090544, 0...\n",
       "1_0      [0.011106509026273262, 0.04718035275929226, 0....\n",
       "1_0      [0.02273952029665867, 0.012984730675280652, 0....\n",
       "1_3      [0.01490580896160797, 0.01848735693603362, 0.0...\n",
       "1_3      [0.015098579258906867, 0.04213589226354767, 0....\n",
       "                               ...                        \n",
       "111_0    [0.012533136074229538, 0.053418867576108996, 0...\n",
       "111_0    [0.005666031131084483, 0.027376618405313045, 0...\n",
       "112_0    [0.009604285933954758, 0.0415964636892555, 0.0...\n",
       "112_0    [0.00989493214077471, 0.010479544271642398, 0....\n",
       "112_0    [0.0037244231015161403, 0.030887391981763344, ...\n",
       "Name: video_features, Length: 2453, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[val_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "742c4d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0_2    [0.017850095385115426, 0.02365287144572545, 0....\n",
       "0_2    [0.012740027625412176, 0.01689307334099398, 0....\n",
       "Name: video_features, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[test_ids][\"0_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ce1bea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iemocap",
   "language": "python",
   "name": "iemocap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
